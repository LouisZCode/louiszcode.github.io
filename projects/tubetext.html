<!DOCTYPE html>
<html lang="en" data-theme="dark">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TubeText - Case Study | Luis Zermeno</title>
    <link rel="canonical" href="https://www.luiszermeno.info/projects/tubetext.html">
    <link rel="icon" href="../favicon.ico" type="image/x-icon">
    <meta name="description" content="TubeText - AI-powered YouTube transcript extraction with LLM summaries, streaming translation, and audio transcription. Built with FastAPI, LangChain, OpenAI, Deepgram, Cerebras.">
    <meta name="keywords" content="YouTube transcription, AI summarization, FastAPI, LangChain, Deepgram, OpenAI, Python, SSE streaming">

    <!-- Fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">

    <!-- Design System -->
    <link rel="stylesheet" href="../css/styles.css">
</head>
<body>

    <!-- Navigation -->
    <nav class="detail-nav">
        <a href="../index.html#projects" class="detail-back">
            <svg width="20" height="20" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 19l-7-7m0 0l7-7m-7 7h18"></path></svg>
            Back to Projects
        </a>

        <div class="detail-nav-right">
            <div class="lang-switcher">
                <button class="lang-btn active" data-lang="en">EN</button>
                <button class="lang-btn" data-lang="de">DE</button>
                <button class="lang-btn" data-lang="es">ES</button>
            </div>
            <button class="theme-toggle" data-i18n="theme-light">Light Mode</button>
        </div>
    </nav>

    <!-- Hero Section -->
    <header class="detail-hero">
        <div class="detail-hero-content">
            <div class="detail-badge">
                <span class="detail-badge-dot"></span>
                <span data-i18n="project-status-live">Live Product</span>
            </div>
            <h1>
                TubeText: <br>
                <span class="accent">AI Transcript Engine</span>
            </h1>
            <p class="detail-hero-desc" data-i18n="tt-description">
                An async backend that orchestrates multiple AI services to extract, summarize, and translate YouTube video content — turning hours of video into actionable text in seconds.
            </p>

            <div class="detail-hero-actions">
                <a href="https://tubetext.app" target="_blank" class="btn btn-primary">
                    Visit Live Site
                    <svg width="16" height="16" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 6H6a2 2 0 00-2 2v10a2 2 0 002 2h10a2 2 0 002-2v-4M14 4h6m0 0v6m0-6L10 14"></path></svg>
                </a>
                <a href="https://github.com/LouisZCode/Youtube-2-Text" target="_blank" class="btn btn-ghost">
                    <svg width="20" height="20" fill="currentColor" viewBox="0 0 24 24"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
                    View Source
                </a>
            </div>
        </div>

        <!-- Hero Visual -->
        <div class="detail-hero-visual">
            <img src="../images/tubetext-demo.gif" alt="TubeText Demo" onerror="this.src='../images/tubetext_small.png'">
            <div class="detail-stat-badge">
                <div class="label">AI Services</div>
                <div class="value">3</div>
            </div>
        </div>
    </header>

    <!-- Technical Specs Bar -->
    <section class="specs-bar">
        <div class="specs-bar-inner">
            <div>
                <h3 data-i18n="tt-spec-framework">Stack</h3>
                <p>FastAPI, Python, LangChain</p>
            </div>
            <div>
                <h3 data-i18n="tt-spec-ai">AI Services</h3>
                <p>OpenAI, Deepgram, Cerebras</p>
            </div>
            <div>
                <h3 data-i18n="tt-spec-database">Database</h3>
                <p>PostgreSQL + SQLAlchemy</p>
            </div>
            <div>
                <h3 data-i18n="tt-spec-deployment">Deployment</h3>
                <p>Docker + Railway</p>
            </div>
        </div>
    </section>

    <!-- Main Content -->
    <div class="detail-main">

        <!-- Left Column - Main Content -->
        <div class="detail-content">

            <!-- The Challenge -->
            <section>
                <h2 data-i18n="tt-challenge">The Challenge</h2>
                <p data-i18n="tt-challenge-p1">
                    YouTube is one of the richest knowledge sources on the internet — tutorials, lectures, interviews, deep dives on any topic. But most videos are long, full of filler, and hard to skim. Getting to the content that matters means watching everything.
                </p>
                <p data-i18n="tt-challenge-p2">
                    The technical challenge was building an <strong>async pipeline</strong> that orchestrates multiple AI services (transcription, summarization, translation) without blocking — while keeping response times fast enough for a real-time user experience.
                </p>
            </section>

            <!-- AI Pipeline Architecture -->
            <section>
                <h2 data-i18n="tt-pipeline">AI Pipeline Architecture</h2>
                <div class="detail-diagram">
                    <img src="../images/tubetext-flow.png" alt="TubeText AI Pipeline Architecture">
                    <p class="caption">Full AI pipeline from URL to translated transcript</p>
                </div>
            </section>

            <!-- LangChain Summary Agent -->
            <section>
                <h2 data-i18n="tt-summary-agent">LangChain Summary Agent</h2>
                <p data-i18n="tt-summary-agent-desc">
                    Summaries are generated through a LangChain agent with YAML-driven prompts. This keeps prompt engineering separate from application logic, making it easy to iterate on prompt quality without touching code.
                </p>

                <div class="code-block">
                    <div class="code-block-header">
                        <span class="code-block-dot red"></span>
                        <span class="code-block-dot yellow"></span>
                        <span class="code-block-dot green"></span>
                        <span class="code-block-filename">agents/summarize_agent.py</span>
                    </div>
                    <pre><code><span class="kw">from</span> langchain.agents <span class="kw">import</span> create_agent
<span class="kw">import</span> yaml

<span class="comment"># Load prompt from YAML config</span>
<span class="kw">def</span> <span class="fn">load_prompts</span>():
    <span class="kw">with</span> open(<span class="str">"agents/prompts.yaml"</span>, <span class="str">"r"</span>, encoding=<span class="str">"utf-8"</span>) <span class="kw">as</span> f:
        <span class="kw">return</span> yaml.safe_load(f)

prompts = load_prompts()

summary_agent = create_agent(
    model=<span class="str">"openai:gpt-5-mini"</span>,
    system_prompt=prompts[<span class="str">"SUMMARIZE_PROMPT"</span>]
)

<span class="comment"># Invoked async from the route handler</span>
result = <span class="kw">await</span> summary_agent.ainvoke(
    {<span class="str">"messages"</span>: [{<span class="str">"role"</span>: <span class="str">"user"</span>, <span class="str">"content"</span>: transcript_text}]}
)
summary = result[<span class="str">"messages"</span>][-<span class="num">1</span>].content</code></pre>
                </div>
            </section>

            <!-- Streaming Translation -->
            <section>
                <h2 data-i18n="tt-streaming">Real-Time Streaming Translation</h2>
                <p data-i18n="tt-streaming-desc">
                    Translation uses Server-Sent Events (SSE) to stream results segment by segment. Cerebras GPT-OSS-120b was chosen for its fast inference speed, giving users real-time feedback instead of waiting for the entire transcript to translate.
                </p>

                <div class="code-block">
                    <div class="code-block-header">
                        <span class="code-block-dot red"></span>
                        <span class="code-block-dot yellow"></span>
                        <span class="code-block-dot green"></span>
                        <span class="code-block-filename">agents/translate_agent.py</span>
                    </div>
                    <pre><code><span class="kw">from</span> cerebras.cloud.sdk <span class="kw">import</span> AsyncCerebras
<span class="kw">import</span> yaml, os

prompts = yaml.safe_load(open(<span class="str">"agents/prompts.yaml"</span>))
translate_prompt = prompts[<span class="str">"TRANSLATE_PROMPT"</span>]
client = AsyncCerebras(api_key=os.environ.get(<span class="str">"CEREBRAS_API_KEY"</span>))

<span class="kw">async def</span> <span class="fn">translate</span>(text: str, language: str) -> str:
    response = <span class="kw">await</span> client.chat.completions.create(
        model=<span class="str">"gpt-oss-120b"</span>,
        messages=[
            {<span class="str">"role"</span>: <span class="str">"system"</span>, <span class="str">"content"</span>: translate_prompt},
            {<span class="str">"role"</span>: <span class="str">"user"</span>, <span class="str">"content"</span>: f<span class="str">"Translate to {language}:\n\n{text}"</span>},
        ],
    )
    <span class="kw">return</span> response.choices[<span class="num">0</span>].message.content</code></pre>
                </div>

                <div class="code-block">
                    <div class="code-block-header">
                        <span class="code-block-dot red"></span>
                        <span class="code-block-dot yellow"></span>
                        <span class="code-block-dot green"></span>
                        <span class="code-block-filename">routes/translate_router.py</span>
                    </div>
                    <pre><code><span class="kw">async def</span> <span class="fn">event_generator</span>():
    <span class="str">"""Yield SSE events as each segment is translated."""</span>
    <span class="kw">for</span> i <span class="kw">in</span> range(<span class="num">0</span>, len(request.segments), CHUNK_SIZE):
        chunk_text = <span class="str">" "</span>.join(seg.text <span class="kw">for</span> seg <span class="kw">in</span> request.segments[i:i+<span class="num">1</span>])
        translated = <span class="kw">await</span> translate(chunk_text, request.language)
        <span class="kw">yield</span> f<span class="str">"data: {json.dumps({'translation': translated})}\n\n"</span>
    <span class="kw">yield</span> f<span class="str">"data: {json.dumps({'done': True})}\n\n"</span>

<span class="kw">return</span> StreamingResponse(
    event_generator(),
    media_type=<span class="str">"text/event-stream"</span>,
    headers={<span class="str">"Cache-Control"</span>: <span class="str">"no-cache"</span>, <span class="str">"X-Accel-Buffering"</span>: <span class="str">"no"</span>},
)</code></pre>
                </div>
            </section>

            <!-- Async Database Layer -->
            <section>
                <h2 data-i18n="tt-async-db">Async Database Layer</h2>
                <p data-i18n="tt-async-db-desc">
                    The entire data layer is async — PostgreSQL via asyncpg with SQLAlchemy 2.0 async sessions. Alembic handles schema migrations. Usage tracking resets automatically on calendar month boundaries without any background jobs.
                </p>

                <div class="code-block">
                    <div class="code-block-header">
                        <span class="code-block-dot red"></span>
                        <span class="code-block-dot yellow"></span>
                        <span class="code-block-dot green"></span>
                        <span class="code-block-filename">database/connection.py</span>
                    </div>
                    <pre><code><span class="kw">from</span> sqlalchemy.ext.asyncio <span class="kw">import</span> create_async_engine, async_sessionmaker
<span class="kw">import</span> os

<span class="comment"># Auto-convert to asyncpg driver</span>
database_url = os.getenv(<span class="str">"DATABASE_URL"</span>)
<span class="kw">if</span> database_url <span class="kw">and</span> database_url.startswith(<span class="str">"postgresql://"</span>):
    database_url = database_url.replace(<span class="str">"postgresql://"</span>, <span class="str">"postgresql+asyncpg://"</span>, <span class="num">1</span>)

engine = create_async_engine(database_url)
SessionLocal = async_sessionmaker(
    bind=engine, autoflush=<span class="kw">False</span>, autocommit=<span class="kw">False</span>
)

<span class="kw">async def</span> <span class="fn">get_db</span>():
    <span class="kw">async with</span> SessionLocal() <span class="kw">as</span> db:
        <span class="kw">yield</span> db</code></pre>
                </div>
            </section>

            <!-- System Design Tradeoffs -->
            <section>
                <h2 data-i18n="tt-tradeoffs">System Design Tradeoffs</h2>
                <p data-i18n="tt-tradeoffs-intro">
                    Every architectural choice has a cost. Here are the key tradeoffs I made and why.
                </p>

                <div class="code-block">
                    <div class="code-block-header">
                        <span class="code-block-dot red"></span>
                        <span class="code-block-dot yellow"></span>
                        <span class="code-block-dot green"></span>
                        <span class="code-block-filename">architecture_decisions.md</span>
                    </div>
                    <pre><code><span class="comment"># ADR-001: Signed cookies for anonymous users</span>
<span class="str">Decision:</span>  Track anonymous usage via signed HTTP-only cookies
<span class="str">Why:</span>       No DB pollution — only a counter, no rows until signup
<span class="str">Tradeoff:</span>  Counter resets if cookie clears (acceptable for free tier)

<span class="comment"># ADR-002: JWT in HTTP-only cookies</span>
<span class="str">Decision:</span>  Store auth tokens as HTTP-only cookies, not localStorage
<span class="str">Why:</span>       XSS-safe — browser sends automatically, JS can't access
<span class="str">Tradeoff:</span>  Can't read token from JS (by design)

<span class="comment"># ADR-003: PostgreSQL as single data store</span>
<span class="str">Decision:</span>  Async PostgreSQL via asyncpg — no Redis, no cache layer
<span class="str">Why:</span>       Simpler infra, fewer moving parts to maintain
<span class="str">Tradeoff:</span>  Requires careful handling of SQLAlchemy async patterns

<span class="comment"># ADR-004: SSE for translation streaming</span>
<span class="str">Decision:</span>  Server-Sent Events over WebSockets
<span class="str">Why:</span>       Simpler than WebSockets for one-way data flow
<span class="str">Tradeoff:</span>  HTTP 200 already sent — mid-stream errors need SSE error events

<span class="comment"># ADR-005: Cerebras for translation</span>
<span class="str">Decision:</span>  Cerebras GPT-OSS-120b instead of OpenAI for translation
<span class="str">Why:</span>       Fastest inference speed available, free tier
<span class="str">Tradeoff:</span>  Less model variety, models can be deprecated

<span class="comment"># ADR-006: Deepgram for premium transcription</span>
<span class="str">Decision:</span>  Deepgram Nova-3 for videos without captions
<span class="str">Why:</span>       Handles any video regardless of caption availability
<span class="str">Tradeoff:</span>  Adds yt-dlp + ffmpeg dependency — heavier infra</code></pre>
                </div>
            </section>

        </div>

        <!-- Right Column - Sidebar -->
        <aside class="detail-sidebar">

            <!-- Key Features -->
            <div class="sidebar-card">
                <h3 data-i18n="tt-features">Key Features</h3>
                <ul class="sidebar-features">
                    <li>
                        <svg width="20" height="20" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <span data-i18n="tt-feature1">Caption-based transcript extraction</span>
                    </li>
                    <li>
                        <svg width="20" height="20" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <span data-i18n="tt-feature2">Audio transcription via Deepgram Nova-3</span>
                    </li>
                    <li>
                        <svg width="20" height="20" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <span data-i18n="tt-feature3">AI summaries with LangChain + GPT-4 mini</span>
                    </li>
                    <li>
                        <svg width="20" height="20" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <span data-i18n="tt-feature4">Real-time streaming translation (SSE)</span>
                    </li>
                    <li>
                        <svg width="20" height="20" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <span data-i18n="tt-feature5">PDF export with branding</span>
                    </li>
                    <li>
                        <svg width="20" height="20" fill="none" stroke="currentColor" viewBox="0 0 24 24"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M5 13l4 4L19 7"></path></svg>
                        <span data-i18n="tt-feature6">Google OAuth + Stripe billing</span>
                    </li>
                </ul>
            </div>

            <!-- Lessons Learned -->
            <div class="sidebar-card">
                <h3 data-i18n="tt-lessons">Lessons Learned</h3>
                <div class="sidebar-lessons">
                    <div>
                        <strong data-i18n="tt-lesson1-title">Async SQLAlchemy Gotchas</strong>
                        <p data-i18n="tt-lesson1-desc">
                            SQLAlchemy expires attributes after commit() — accessing them triggers a sync lazy-load that crashes async sessions (MissingGreenlet). Fixed with explicit db.refresh() after every commit.
                        </p>
                    </div>
                    <div>
                        <strong data-i18n="tt-lesson2-title">SSE Error Handling</strong>
                        <p data-i18n="tt-lesson2-desc">
                            Once an SSE stream sends HTTP 200, you can't return error status codes mid-stream. Had to implement SSE error events so the frontend can detect and handle failures gracefully.
                        </p>
                    </div>
                    <div>
                        <strong data-i18n="tt-lesson3-title">OAuth Behind Reverse Proxies</strong>
                        <p data-i18n="tt-lesson3-desc">
                            Railway's proxy strips HTTPS, so FastAPI generated http:// redirect URIs — causing redirect_uri_mismatch with Google OAuth. Fixed with ProxyHeadersMiddleware to read X-Forwarded-Proto.
                        </p>
                    </div>
                    <div>
                        <strong data-i18n="tt-lesson4-title">Build-Time vs Runtime Env Vars</strong>
                        <p data-i18n="tt-lesson4-desc">
                            NEXT_PUBLIC_ vars are baked at build time, but Railway injects env vars at runtime only. Docker builds get undefined values unless you hardcode with ENV before the build step.
                        </p>
                    </div>
                </div>
            </div>


        </aside>

    </div>

    <!-- Footer -->
    <footer class="detail-footer">
        <div class="detail-footer-links">
            <a href="https://tubetext.app" target="_blank">Live Site &rarr;</a>
            <a href="https://github.com/LouisZCode/Youtube-2-Text" target="_blank">Source Code &rarr;</a>
        </div>
        <a href="../index.html#projects" class="detail-footer-back">&larr; Back to Portfolio Home</a>
    </footer>

    <script src="../js/i18n.js"></script>
    <script src="../js/main.js"></script>
</body>
</html>
