<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Agent with Voice - Luis Zermeno</title>
    <link rel="stylesheet" href="../css/style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <!-- Domain canonical reference -->
    <link rel="canonical" href="https://www.luiszermeno.info/projects/ai-agent-voice.html">
    <!-- Favicon and touch icons -->
    <link rel="icon" href="../favicon.ico" type="image/x-icon">
    <link rel="shortcut icon" href="../favicon.ico" type="image/x-icon">
    <!-- SEO Meta Tags -->
    <meta name="description" content="AI Agent with Voice - A Python application that enables natural voice interaction with large language models through speech recognition and text-to-speech capabilities.">
    <meta name="keywords" content="AI voice assistant, speech recognition, text-to-speech, Ollama, Python, LLM, voice interface, AI development, MVC architecture, offline voice recognition">
</head>
<body>
    <header>
        <nav class="navbar">
            <div class="logo">
                <a href="../index.html">Luis Zermeno</a>
            </div>
            <div class="profile-circle">
                <img src="../images/profile_luis.png" alt="Luis Zermeno">
            </div>
            <ul class="nav-links">
                <li><a href="../index.html" data-i18n="nav-home">Home</a></li>
                <li><a href="../experience.html" data-i18n="nav-experience">Experience</a></li>
                <li><a href="../portfolio.html" class="active" data-i18n="nav-portfolio">Portfolio</a></li>
            </ul>
            <div class="language-switcher">
                <button class="lang-btn active" data-lang="en">EN</button>
                <button class="lang-btn" data-lang="de">DE</button>
                <button class="lang-btn" data-lang="es">ES</button>
            </div>
            <div class="hamburger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </nav>
    </header>

    <main class="project-details">
        <div class="container">
            <div class="project-header">
                <h1>AI Agent with Voice</h1>
                <div class="project-meta">
                    <span class="project-category"><i class="fas fa-robot"></i> AI Assistant Development</span>
                    <span class="project-date"><i class="far fa-calendar-alt"></i> March 2025</span>
                    <span class="project-duration"><i class="far fa-clock"></i> Personal Project</span>
                    <span class="project-link"><i class="fas fa-external-link-alt"></i> <a href="https://github.com/louiszcode/ai_agent_with_voice" target="_blank">GitHub Repository</a></span>
                </div>
            </div>

            <div class="project-showcase">
                <div class="project-image">
                    <img src="../images/ai-agent-voice.svg" alt="AI Agent with Voice Interface" class="main-image">
                </div>
                <div class="project-thumbnail-grid">
                    <img src="../images/ai-agent-voice-1.svg" alt="Voice Recognition Interface" class="thumbnail" onclick="changeMainImage(this.src)">
                    <img src="../images/ai-agent-voice-2.svg" alt="Text-to-Speech Component" class="thumbnail" onclick="changeMainImage(this.src)">
                    <img src="../images/ai_agent_voice.svg" alt="Application Architecture" class="thumbnail" onclick="changeMainImage(this.src)">
                </div>
            </div>

            <div class="project-content">
                <div class="project-description">
                    <h2>Project Overview</h2>
                    <p>
                        The AI Agent with Voice is a Python-based application that extends the functionality of large language models (LLMs) by adding speech input and output capabilities. It creates a natural voice interface that allows users to have spoken conversations with AI models running locally through Ollama.
                    </p>
                    <p>
                        This project combines offline speech recognition with high-quality text-to-speech to provide a seamless conversational experience. By implementing a Model-View-Controller (MVC) architecture, the application maintains a clean separation of concerns, making it both maintainable and extensible.
                    </p>
                    <p>
                        Unlike cloud-based voice assistants, this application focuses on privacy by processing all speech locally, while still delivering a responsive and natural interaction experience. Users can choose from multiple voice options and connect to different language models based on their needs.
                    </p>
                </div>

                <div class="project-features">
                    <h2>Key Features</h2>
                    <ul>
                        <li>
                            <strong>Voice Input:</strong> Offline speech recognition using the Vosk library for private, accurate transcription of user speech.
                        </li>
                        <li>
                            <strong>Voice Output:</strong> Dual text-to-speech engines with XTTS-v2 for high-quality natural-sounding voices and system TTS as a fallback option.
                        </li>
                        <li>
                            <strong>Conversation Display:</strong> Color-coded conversation history that shows both user inputs and AI responses for easy reference.
                        </li>
                        <li>
                            <strong>Multiple LLM Support:</strong> Connect to different language models through Ollama, allowing users to choose the most appropriate model for their needs.
                        </li>
                        <li>
                            <strong>Voice Selection:</strong> Choice of multiple voices for AI responses, with support for custom voice cloning.
                        </li>
                        <li>
                            <strong>MVC Architecture:</strong> Clean separation of concerns with model for AI logic, view for UI, and controller for connecting components.
                        </li>
                        <li>
                            <strong>Offline Operation:</strong> All speech processing happens locally, protecting user privacy and allowing operation without internet connectivity.
                        </li>
                    </ul>
                </div>

                <div class="project-development">
                    <h2>Development Process</h2>
                    <p>
                        The development of this project focused on creating a modular, extensible system that could provide a natural voice interface to AI models while maintaining user privacy and control. The project was built using Python and several specialized libraries.
                    </p>
                    <p>
                        The development process included:
                    </p>
                    <ul>
                        <li>Designing a flexible MVC architecture to separate the AI logic, user interface, and control flow</li>
                        <li>Implementing offline speech recognition using Vosk for privacy-focused voice input</li>
                        <li>Building a hybrid text-to-speech system with XTTS-v2 for high-quality voices and system TTS as a reliable fallback</li>
                        <li>Creating a responsive TKinter interface with intuitive controls and conversation history</li>
                        <li>Developing an Ollama integration for connecting to locally running language models</li>
                        <li>Implementing voice selection and custom voice options</li>
                        <li>Thorough testing and optimization for responsiveness and performance</li>
                    </ul>
                </div>

                <div class="technical-details">
                    <h2>Technical Highlights</h2>
                    <div class="tech-stack">
                        <div class="tech-item">
                            <i class="fab fa-python"></i>
                            <h3>Python</h3>
                            <p>Core language used for application development with various specialized libraries</p>
                        </div>
                        <div class="tech-item">
                            <i class="fas fa-microphone"></i>
                            <h3>Vosk</h3>
                            <p>Offline speech recognition engine for private, accurate voice input processing</p>
                        </div>
                        <div class="tech-item">
                            <i class="fas fa-volume-up"></i>
                            <h3>XTTS-v2</h3>
                            <p>Advanced deep learning text-to-speech for natural-sounding AI responses</p>
                        </div>
                        <div class="tech-item">
                            <i class="fas fa-desktop"></i>
                            <h3>TKinter</h3>
                            <p>Python's built-in GUI toolkit used to create the user interface</p>
                        </div>
                        <div class="tech-item">
                            <i class="fas fa-brain"></i>
                            <h3>Ollama</h3>
                            <p>Local LLM server for running AI models without cloud dependencies</p>
                        </div>
                        <div class="tech-item">
                            <i class="fas fa-project-diagram"></i>
                            <h3>MVC Architecture</h3>
                            <p>Software design pattern used for clean separation of concerns</p>
                        </div>
                    </div>
                </div>
                
                <div class="project-challenges">
                    <h2>Challenges & Solutions</h2>
                    <div class="challenge-item">
                        <h3>Voice Recognition Accuracy</h3>
                        <p><strong>Challenge:</strong> Achieving reliable speech recognition without relying on cloud-based services.</p>
                        <p><strong>Solution:</strong> Implemented Vosk, an offline speech recognition system with customizable models, and added silence detection with adaptive thresholds to improve accuracy in different environments.</p>
                    </div>
                    <div class="challenge-item">
                        <h3>Natural-Sounding Speech</h3>
                        <p><strong>Challenge:</strong> Creating natural-sounding AI voices that don't break immersion during conversation.</p>
                        <p><strong>Solution:</strong> Integrated XTTS-v2, a state-of-the-art neural text-to-speech system, while maintaining system TTS as a fallback. Added sentence splitting for better prosody and custom voice support.</p>
                    </div>
                    <div class="challenge-item">
                        <h3>System Performance</h3>
                        <p><strong>Challenge:</strong> Ensuring responsive performance despite running speech recognition, LLM inference, and TTS simultaneously.</p>
                        <p><strong>Solution:</strong> Implemented a multi-threaded architecture with background processing for speech recognition and TTS, along with asynchronous processing of audio to maintain UI responsiveness.</p>
                    </div>
                    <div class="challenge-item">
                        <h3>Cross-Platform Compatibility</h3>
                        <p><strong>Challenge:</strong> Creating a consistent experience across different operating systems.</p>
                        <p><strong>Solution:</strong> Designed fallback mechanisms for both speech recognition and TTS that automatically adapt to available system resources and capabilities.</p>
                    </div>
                </div>

                <div class="project-results">
                    <h2>Results & Implementation Details</h2>
                    <p>
                        The AI Agent with Voice project successfully creates a seamless voice interface for interacting with AI models. The application demonstrates how advanced speech technologies can be combined with local LLMs to create privacy-focused voice assistants.
                    </p>
                    <p>
                        The implementation follows the MVC pattern:
                    </p>
                    <ul>
                        <li><strong>Model (model.py):</strong> Handles communication with Ollama, maintains conversation history, and processes AI responses</li>
                        <li><strong>View (view.py):</strong> Implements the TKinter GUI with user controls and conversation display</li>
                        <li><strong>Controller (controller.py):</strong> Connects the model and view, manages speech recognition and TTS components</li>
                    </ul>
                    <p>
                        Specialized components include:
                    </p>
                    <ul>
                        <li><strong>Speech Recognition (speech.py):</strong> Implements real-time voice input with Vosk, supporting word-by-word feedback and adaptive silence detection</li>
                        <li><strong>Text-to-Speech (tts.py):</strong> Provides high-quality voice output with XTTS-v2, with system TTS fallback and custom voice support</li>
                    </ul>
                    <p>
                        Key learning outcomes from this project include:
                    </p>
                    <ul>
                        <li>Building MVC-structured applications for complex AI projects</li>
                        <li>Working with offline speech recognition and neural TTS systems</li>
                        <li>Creating responsive, multi-threaded applications that handle resource-intensive AI tasks</li>
                        <li>Designing user interfaces that provide natural conversation experiences</li>
                        <li>Integrating with local LLM servers for privacy-focused AI applications</li>
                    </ul>
                </div>

                <div class="project-links-section">
                    <h2>Links & Resources</h2>
                    <div class="links-grid">
                        <a href="https://github.com/louiszcode/ai_agent_with_voice" target="_blank" class="link-card github">
                            <i class="fab fa-github"></i>
                            <span>GitHub Repository</span>
                        </a>
                        <a href="#" class="link-card documentation">
                            <i class="fas fa-file-alt"></i>
                            <span>Documentation</span>
                        </a>
                        <a href="#" class="link-card website">
                            <i class="fas fa-download"></i>
                            <span>Download Release</span>
                        </a>
                        <a href="#" class="link-card gameplay">
                            <i class="fab fa-youtube"></i>
                            <span>Demo Video</span>
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </main>

    <footer>
        <div class="container">
            <div class="footer-content">
                <p>© 2025 Luis Zermeno. All Rights Reserved.</p>
                <div class="social-links">
                    <a href="https://github.com/louiszcode" target="_blank"><i class="fab fa-github"></i></a>
                    <a href="https://www.linkedin.com/in/luis-zermeno-3b2210108/" target="_blank"><i class="fab fa-linkedin"></i></a>
                </div>
            </div>
        </div>
    </footer>

    <button id="back-to-top" class="back-to-top-btn" title="Back to Top">
        <i class="fas fa-arrow-up"></i>
    </button>

    <script>
        // Handle fallback for PNG to SVG if PNG is not available
        function checkImageSrc(img) {
            if (img.src.endsWith('.png') && img.naturalWidth === 0) {
                img.src = img.src.replace('.png', '.svg');
            }
        }
        
        // Initialize all images with error handlers
        document.addEventListener('DOMContentLoaded', function() {
            const images = document.querySelectorAll('img');
            images.forEach(img => {
                img.addEventListener('error', function() {
                    if (img.src.endsWith('.png')) {
                        img.src = img.src.replace('.png', '.svg');
                    }
                });
            });
        });
        
        // Function to change the main image
        function changeMainImage(src) {
            const mainImage = document.querySelector('.main-image');
            mainImage.src = src;
            // If PNG fails, try SVG
            mainImage.addEventListener('error', function() {
                if (mainImage.src.endsWith('.png')) {
                    mainImage.src = mainImage.src.replace('.png', '.svg');
                }
            });
        }
    </script>
    <script src="../js/main.js"></script>
    <script src="../js/i18n.js"></script>
</body>
</html>